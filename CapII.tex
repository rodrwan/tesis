\chapter[Trabajos relacionados ]{Trabajos relacionados }\label{ch:capitulo2}

En visión por computadora, una de las tareas más llamativas es poder crear algoritmos que sean capaces de recibir una imagen como entrada y crear una representación que describa al objeto o los objetos que estén presentes en dicha imagen, es por esto que pasaremos a discutir algunos de los algoritmo creados, tanto para la detección como para el reconocimiento de objetos y expresiones faciales. Esta sección comprende el detalle de las técnicas de detección y reconocimiento, áreas que de por sí, son extensas, trataremos de abarcar aquellas investigación que sean un aporte y nos ayuden a crear las bases para nuestro trabajo.

% SECCION DE DETECCION 
\section{Detección y reconocimiento}
La detección de objetos es una tarea ardua que ha sido estudiada durante décadas. El fin de detectar objetos, es lograr obtener una representación fiel del objeto que se quiere detectar, extrayendo así, por ejemplo, sus características únicas, logrando crear una interpretación del objeto, que posteriormente será utilizada para su reconocimiento y clasificación.
En cuanto al reconocimiento se han realizado estudios en 2 contextos: objetos rígidos en 2D y objetos en 3D aparte del reconocimiento de caracteres, que en los últimos años a sido campo de estudio, ya que la información necesaria para hacer estos estudios es más acotada. El objetivo principal del \textit{reconocimiento}, es poder clasificar de forma correcta las clases que se están observando. A modo de ejemplo, en una escena donde hay 7 perros y 3 gatos, el objetivo del algoritmo que se utilice es que identifique con el menor error posible que los 7 perros que hay en una escena sean perros y lo mismo para los 3 gatos.
\subsection{Modelo}
Un modelo, es una abstracción teórica del mundo real, el cual permite hacer predicciones sobre la información que estamos analizando. Estos modelos buscan hacer el \textit{match}, entre los descriptores (etapa de detección), de las diversas imágenes. Por lo general se tiene un conjunto de entrenamiento, el cual sirve para dar a conocer las características principales de una imagen. Estas características son extraídas por los descriptores y luego procesadas por los algoritmos de clasificación o de reconocimiento.

\subsection{Modelos de detección y reconocimiento para objetos}
En Torres-Méndez et al.~\cite{trsi2000}, se presenta un modelo de reconocimiento de objetos, que es invariante a la posición de éste, a su rotación y su escala. Se presenta un algoritmo que en primera instancia, pre-procesa los datos, con el fin de normalizar los momentos de inercia que posee el objeto, extrayendo así las características topológicas del objetos. En una segunda fase, el reconocimiento propiamente tal, es logrado usando el algoritmo, \textit{holographic nearest-neighbor (HNN)}.

También en Amit~\cite{2dobject2002}, se presentan técnicas como: \textit{Búsqueda del espacio correspondiente}, el cual realiza una búsqueda sistemática, para el conjunto de características locales de la imagen. En este caso las coincidencias deben satisfacer ciertas restricciones. Restricciones únicas implican una relación directa entre las características del modelo y las características de la imagen. Restricciones binarias implican la relación entre un par de características del modelo y de un par de características de la imagen. Diversas técnicas basadas en heurísticas de árboles se emplean para encontrar los diversos emparejamientos, con el fin de encontrar el emparejamiento óptimo de estas características.

En Amit~\cite{2dobject2002}, se presentan varios modelos para reconocimiento de objetos, muchos de ellos utilizados por estudios realizados en esta área. Por ejemplo, \textit{Deformable-Template Models}, el cual es una representación de alto nivel para un objeto, es decir, es un modelo estadístico, el cual describe la variabilidad que posee un instancia de un objeto en términos de una probabilidad a priori. Además, una representación  estadística de la imagen, entrega una particular deformación de la porción del objeto analizado. La combinación de ésta representación y la probabilidad priori, definen una distribución posterior de la deformación que posee la imagen.

Lowe~\cite{sift2004} presenta un método para la extracción de características invariantes de una imagen que son utilizadas para hacer una comparación entre diferentes vistas o escenas de un objeto. Las características son invariantes a la escala de la imagen y la rotación que esta pueda presentar. Por el lado de los descriptores, estos se representan con la dirección y el gradiente que poseen los puntos de interés encontrados en etapas previas, luego se preprocesan los datos con una función de peso gaussiana, la cual asigna un peso a cada uno de los puntos. El propósito de este filtro es evitar que las muestras sufran variaciones.

En Bernstein~\cite{statistical2005}, se propone un modelo denso y con un rendimiento que otorga una tasa de clasificación alta, este modelo consiste en en una mejora a los modelos \textit{Sparse}, descritos por Amit~\cite{2dobject2002}.

Bay et al.~\cite{surf2008} presenta un detector y descriptor que es invariante a las rotaciones, llamado SURF (Speeded-Up Robust Feature). Como lo que nos interesa son los descriptores, SURF utiliza un descriptor basado en distribuciones. Para SURF la creación de un descriptor debe ser único e invariante al ruido. Para esto cada descriptor describe una distribución de intensidad de los puntos adyacentes al punto de interés, similar a lo que se postula en Lowe~\cite{sift2004}, pero con la diferencia que no se utiliza el gradiente sino que una distribución de primer orden basado en los wavelet the Haar.

Ramanan et al.~\cite{Felzenszwalb2010} presenta un modelo basado en partes,  el cual utiliza varias partes de la imagen con el fin de determinar si existe un objeto de interés en ella. En este trabajo se busca optimizar \textit{Dalal-Triggs detector} el que utiliza un único filtro de HOG~\cite{hog2005}. Este tiene como principal objetivo obtener características específicas del objeto mediante la dirección de los gradientes o bordes, esto es implementado de la siguiente forma: Se divide la imagen en pequeñas porciones, llamadas celdas, las cuales generan otros histogramas de gradientes o bordes por cada pixel dentro de esta celda, combinando estos se obtiene la representación del descriptor. La mejora realizada sobre este método es que en paralelo se computa una función que maximiza los puntos obtenidos por HOG, lo cual permite capturar más características en el mismo espectro de muestreo, este estudio será analizado con mayor detalle en el Capítulo~\ref{ch:capitulo3}, ya que buscaremos hacer un mejora significativa a lo presentado por Ramanan et al.~\cite{Felzenszwalb2010}.

En Jin Choi et al.~\cite{treebased2012}, se propone un modelo basado en el contexto el cual maneja distintas combinaciones o locaciones de objetos que guía un detector el cual produce una interpretación semántica de la imagen que se está analizando. El objetivo de este trabajo es poder detectar múltiples categorías de objetos dentro de una misma escena. Por lo cual su modelo utiliza características globales dependientes entre las categorías de los objetos y las salidas locales de los descriptores utilizados.

\subsection{Modelos de detección y reconocimiento para expresiones}
Comúnmente existen dos enfoques para la extracción de características en el rostro: basados en características geométricas y basados en apariencia, nos enfocaremos en este último ya que es el que más nos puede servir para a lo que deseamos hacer por su naturaleza, puesto que este método utiliza filtros que crean características generales o en una área del rostro en especifico para crear características locales, con el fin de extraer los cambios de apariencia en la imagen del rostro.

Hsu et al.~\cite{Hsu2002}, presentan un algoritmo de detección de rostros, como ellos mismos definen, un detector de rostros humanos juega un importante rol en aplicaciones actuales, es por esto que presentan un algoritmo de detección de rostro que trabaja con imágenes a color, tomando en cuenta distintas condiciones de luminosidad, así como fondos complejos. Dicho algoritmo funciona de la siguiente manera, primero, el algoritmo detecta las regiones donde está presente la piel, y luego genera un rostro candidato basados en la disposición espacial de estos parches cutáneos. Finalmente el algoritmo construye los ojos, boca y el mapa de los contornos, para verificar cada rostro candidato.

Ahone et al.~\cite{ahonen2006}, presentan una representación eficiente del rostro, basándose en las características de las texturas extraídas por LBP, \textit{Local Binary Pattern}. En primera instancia, la imagen es dividida en múltiples regiones donde es utilizado LBP para extraer las características locales de cada región, para luego ser representadas en un vector que contiene todas las regiones del rostro, el cual es utilizado como descriptor.

Ramirez et al.~\cite{ldnp2013} presenta un nuevo descriptor de características locales, llamado Local Directional Number Pattern (LDN), para reconocimiento de rostro y expresiones. Este estudio comenta que la eficiencia de un descriptor depende de su representación y la facilidad de extracción del rostro. Idealmente un descriptor debería tener una alta varianza con clases muy distintas (diferentes personas o expresiones), por otra parte si las clases son semejantes (misma persona o expresión), su varianza debería ser inferior o cero.

Ramanan y Zhu~\cite{Zhu2012} un modelo unificado para detección de rostros, estimación de pose y estimación de contornos, este modelo está basado en una mezcla de árboles que comparten un un conjunto de partes. Se modela cada punto destacado como una parte y se usa una mezcla global para capturar los cambios topológicos de acuerdo al punto de vista que se está analizando. En este estudio se muestra como las técnicas de árboles pueden ser muy eficientes al momento de interpretar las partes que poseen los rostros.


